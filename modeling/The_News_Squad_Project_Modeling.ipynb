{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Online News Popularity\n",
    "### Xiao Chu, Zhentao Hou, Jingwen Yu\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from calendar import day_name\n",
    "from rfpimp import *\n",
    "\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, median_absolute_error, accuracy_score, precision_score,\\\n",
    "                            recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pd.set_option('display.max_columns', 62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_min_min</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>kw_avg_min</th>\n",
       "      <th>kw_min_max</th>\n",
       "      <th>kw_max_max</th>\n",
       "      <th>kw_avg_max</th>\n",
       "      <th>kw_min_avg</th>\n",
       "      <th>kw_max_avg</th>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>LDA_00</th>\n",
       "      <th>LDA_01</th>\n",
       "      <th>LDA_02</th>\n",
       "      <th>LDA_03</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>rate_positive_words</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.378279</td>\n",
       "      <td>0.040005</td>\n",
       "      <td>0.041263</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.378636</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.799756</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.050096</td>\n",
       "      <td>0.050101</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.341246</td>\n",
       "      <td>0.148948</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217792</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.033351</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.682188</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.495833</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.494651</td>\n",
       "      <td>0.028905</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.429850</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>0.041431</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>3151.157895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028633</td>\n",
       "      <td>0.028794</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.513502</td>\n",
       "      <td>0.281003</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.012127</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...      731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/      731.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0            12.0             219.0         0.663594               1.0   \n",
       "1             9.0             255.0         0.604743               1.0   \n",
       "2             9.0             211.0         0.575130               1.0   \n",
       "3             9.0             531.0         0.503788               1.0   \n",
       "4            13.0            1072.0         0.415646               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.815385        4.0             2.0       1.0         0.0   \n",
       "1                  0.791946        3.0             1.0       1.0         0.0   \n",
       "2                  0.663866        3.0             1.0       1.0         0.0   \n",
       "3                  0.665635        9.0             0.0       1.0         0.0   \n",
       "4                  0.540890       19.0            19.0      20.0         0.0   \n",
       "\n",
       "   average_token_length  num_keywords  data_channel_is_lifestyle  \\\n",
       "0              4.680365           5.0                        0.0   \n",
       "1              4.913725           4.0                        0.0   \n",
       "2              4.393365           6.0                        0.0   \n",
       "3              4.404896           7.0                        0.0   \n",
       "4              4.682836           7.0                        0.0   \n",
       "\n",
       "   data_channel_is_entertainment  data_channel_is_bus  data_channel_is_socmed  \\\n",
       "0                            1.0                  0.0                     0.0   \n",
       "1                            0.0                  1.0                     0.0   \n",
       "2                            0.0                  1.0                     0.0   \n",
       "3                            1.0                  0.0                     0.0   \n",
       "4                            0.0                  0.0                     0.0   \n",
       "\n",
       "   data_channel_is_tech  data_channel_is_world  kw_min_min  kw_max_min  \\\n",
       "0                   0.0                    0.0         0.0         0.0   \n",
       "1                   0.0                    0.0         0.0         0.0   \n",
       "2                   0.0                    0.0         0.0         0.0   \n",
       "3                   0.0                    0.0         0.0         0.0   \n",
       "4                   1.0                    0.0         0.0         0.0   \n",
       "\n",
       "   kw_avg_min  kw_min_max  kw_max_max  kw_avg_max  kw_min_avg  kw_max_avg  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   kw_avg_avg  self_reference_min_shares  self_reference_max_shares  \\\n",
       "0         0.0                      496.0                      496.0   \n",
       "1         0.0                        0.0                        0.0   \n",
       "2         0.0                      918.0                      918.0   \n",
       "3         0.0                        0.0                        0.0   \n",
       "4         0.0                      545.0                    16000.0   \n",
       "\n",
       "   self_reference_avg_sharess  weekday_is_monday  weekday_is_tuesday  \\\n",
       "0                  496.000000                1.0                 0.0   \n",
       "1                    0.000000                1.0                 0.0   \n",
       "2                  918.000000                1.0                 0.0   \n",
       "3                    0.000000                1.0                 0.0   \n",
       "4                 3151.157895                1.0                 0.0   \n",
       "\n",
       "   weekday_is_wednesday  weekday_is_thursday  weekday_is_friday  \\\n",
       "0                   0.0                  0.0                0.0   \n",
       "1                   0.0                  0.0                0.0   \n",
       "2                   0.0                  0.0                0.0   \n",
       "3                   0.0                  0.0                0.0   \n",
       "4                   0.0                  0.0                0.0   \n",
       "\n",
       "   weekday_is_saturday  weekday_is_sunday  is_weekend    LDA_00    LDA_01  \\\n",
       "0                  0.0                0.0         0.0  0.500331  0.378279   \n",
       "1                  0.0                0.0         0.0  0.799756  0.050047   \n",
       "2                  0.0                0.0         0.0  0.217792  0.033334   \n",
       "3                  0.0                0.0         0.0  0.028573  0.419300   \n",
       "4                  0.0                0.0         0.0  0.028633  0.028794   \n",
       "\n",
       "     LDA_02    LDA_03    LDA_04  global_subjectivity  \\\n",
       "0  0.040005  0.041263  0.040123             0.521617   \n",
       "1  0.050096  0.050101  0.050001             0.341246   \n",
       "2  0.033351  0.033334  0.682188             0.702222   \n",
       "3  0.494651  0.028905  0.028572             0.429850   \n",
       "4  0.028575  0.028572  0.885427             0.513502   \n",
       "\n",
       "   global_sentiment_polarity  global_rate_positive_words  \\\n",
       "0                   0.092562                    0.045662   \n",
       "1                   0.148948                    0.043137   \n",
       "2                   0.323333                    0.056872   \n",
       "3                   0.100705                    0.041431   \n",
       "4                   0.281003                    0.074627   \n",
       "\n",
       "   global_rate_negative_words  rate_positive_words  rate_negative_words  \\\n",
       "0                    0.013699             0.769231             0.230769   \n",
       "1                    0.015686             0.733333             0.266667   \n",
       "2                    0.009479             0.857143             0.142857   \n",
       "3                    0.020716             0.666667             0.333333   \n",
       "4                    0.012127             0.860215             0.139785   \n",
       "\n",
       "   avg_positive_polarity  min_positive_polarity  max_positive_polarity  \\\n",
       "0               0.378636               0.100000                    0.7   \n",
       "1               0.286915               0.033333                    0.7   \n",
       "2               0.495833               0.100000                    1.0   \n",
       "3               0.385965               0.136364                    0.8   \n",
       "4               0.411127               0.033333                    1.0   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.350000                 -0.600              -0.200000   \n",
       "1              -0.118750                 -0.125              -0.100000   \n",
       "2              -0.466667                 -0.800              -0.133333   \n",
       "3              -0.369697                 -0.600              -0.166667   \n",
       "4              -0.220192                 -0.500              -0.050000   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.500000                 -0.187500                0.000000   \n",
       "1            0.000000                  0.000000                0.500000   \n",
       "2            0.000000                  0.000000                0.500000   \n",
       "3            0.000000                  0.000000                0.500000   \n",
       "4            0.454545                  0.136364                0.045455   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  \n",
       "0                      0.187500     593  \n",
       "1                      0.000000     711  \n",
       "2                      0.000000    1500  \n",
       "3                      0.000000    1200  \n",
       "4                      0.136364     505  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "news = pd.read_csv(\"OnlineNewsPopularity.csv\")\n",
    "\n",
    "# delete the white space before each column name\n",
    "news.columns = [col.strip(\" \") for col in news.columns]\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: insert target exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we checked the feature correlation heatmap and most of the features are uncorrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the feature correlation heatmap\n",
    "corr = plot_corr_heatmap(news, figsize=(20, 20), label_fontsize=9, value_fontsize=7)  # from rfpimp package\n",
    "corr.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we explored the relationship between the target (number of shares) and some selected features:\n",
    "1. number of words in the content vs number of shares\n",
    "2. text sentiment polarity vs number of shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words in the content vs number of shares\n",
    "plt.scatter(news[\"n_tokens_content\"], news[\"shares\"])\n",
    "plt.title(\"Content Lengths vs Number of Shares\", size=15)\n",
    "plt.xlabel(\"Number of Words\", size=12)\n",
    "plt.ylabel(\"Number of Shares\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text sentiment polarity vs number of shares\n",
    "plt.scatter(news[\"global_sentiment_polarity\"], news[\"shares\"])\n",
    "plt.title(\"Text Sentiment Polarity vs Number of Shares\", size=15)\n",
    "plt.xlabel(\"Polarity Score\", size=12)\n",
    "plt.ylabel(\"Number of Shares\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by day of the week\n",
    "news_dow = news.iloc[:, 31:39]\n",
    "news_dow = pd.DataFrame(np.argmax(np.array(news_dow), axis=1))\n",
    "news_dow[\"day_name\"] = news_dow.applymap(lambda x: day_name[x])\n",
    "news_dow = pd.concat([news_dow, news_binary_median[[\"shares\", \"popularity\"]]], axis=1)\n",
    "news_dow.columns = [\"dow\", \"dow_name\", \"counts\", \"popularity\"]\n",
    "news_dow[\"popularity\"] = news_dow[\"popularity\"].apply(lambda x: \"popular\" if x else \"unpopular\")\n",
    "popularity_dow = news_dow.groupby([\"dow\", \"dow_name\", \"popularity\"])[\"counts\"].count().reset_index()\n",
    "popularity_dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot news popularity based on day of the week\n",
    "plt.figure(figsize=(11, 8.5))\n",
    "sns.barplot(x=\"dow_name\", y=\"counts\", hue=\"popularity\", data=popularity_dow, palette=[\"C3\", \"C0\"])\n",
    "plt.title(\"News Popularity vs Day of the Week\\n\", size=24)\n",
    "plt.xlabel(\"\\nDay of the Week\", size=15)\n",
    "plt.xticks(size=15)\n",
    "plt.ylabel(\"News Count\\n\", size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.savefig(fname=\"Popularity by DOW\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by channel\n",
    "channel_dict = {0: \"Lifestyle\", 1: \"Entertainment\", 2: \"Business\", 3: \"Social Media\", 4: \"Technology\", 5: \"World\",\n",
    "                6: \"Other\"}\n",
    "news_channel = news.iloc[:, 13:19]\n",
    "news_channel = news_channel.assign(Other=1)\n",
    "news_channel = pd.DataFrame(np.argmax(np.array(news_channel), axis=1))\n",
    "news_channel[\"channel_name\"] = news_channel.applymap(lambda x: channel_dict[x])\n",
    "news_channel = pd.concat([news_channel, news_binary_median[[\"shares\", \"popularity\"]]], axis=1)\n",
    "news_channel.columns = [\"channel\", \"channel_name\", \"counts\", \"popularity\"]\n",
    "news_channel[\"popularity\"] = news_channel[\"popularity\"].apply(lambda x: \"popular\" if x else \"unpopular\")\n",
    "popularity_channel = news_channel.groupby([\"channel\", \"channel_name\", \"popularity\"])[\"counts\"].count().reset_index()\n",
    "order = list(popularity_channel[popularity_channel[\"popularity\"] == \"popular\"]\n",
    "             .sort_values(\"counts\", ascending=False)[\"channel_name\"])\n",
    "popularity_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot news popularity based on news channel\n",
    "plt.figure(figsize=(14, 11))\n",
    "sns.barplot(x=\"channel_name\", y=\"counts\", hue=\"popularity\", order=order, data=popularity_channel, palette=[\"C3\", \"C0\"])\n",
    "plt.title(\"News Popularity vs News Channel\\n\", size=24)\n",
    "plt.xlabel(\"\\nNews Channel\", size=15)\n",
    "plt.xticks(size=15)\n",
    "plt.ylabel(\"News Count\\n\", size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.savefig(fname=\"Popularity by Channel\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_threshold = news_binary_median.groupby(\"popularity\")[\"shares\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_threshold = news_binary_mean.groupby(\"popularity\")[\"shares\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_threshold = pd.concat([median_threshold, mean_threshold], axis=0).reset_index()\n",
    "popularity_threshold[\"threshold\"] = [\"median\", \"median\", \"mean\", \"mean\"]\n",
    "popularity_threshold.columns = [\"popularity\", \"counts\", \"threshold\"]\n",
    "popularity_threshold[\"popularity\"] = (popularity_threshold[\"popularity\"]\n",
    "                                      .apply(lambda x: \"popular\" if x else \"unpopular\"))\n",
    "popularity_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot news popularity threshold\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.barplot(x=\"threshold\", y=\"counts\", hue=\"popularity\", data=popularity_threshold, palette=[\"C0\", \"C3\"])\n",
    "plt.title(\"Number of Class Instances vs Different Thresholds\\n\", size=16)\n",
    "plt.xlabel(\"Threshold\", size=14)\n",
    "plt.xticks(size=12)\n",
    "plt.ylabel(\"Number of Class Instances\", size=14)\n",
    "plt.yticks(size=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig(fname=\"Threshold\", dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a). Regression\n",
    "Initially, regression models were used to predict the number of shares of a piece of news. All features except for news url and timedelta were included in the model. StandardScaler() was applied to numerical features. Pipelines were created for each regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose features and target\n",
    "X = news.iloc[:, 2:60]  # all columns except url and target\n",
    "y = news[\"shares\"].values.ravel()  # target: number of shares\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create pipelines for different regression algorithms\n",
    "def regr_pipeline():\n",
    "    \"\"\"\n",
    "    Create a pipeline for each regression algorithm:\n",
    "    1. Lasso\n",
    "    2. Ridge\n",
    "    3. Random Forest Regressor\n",
    "    \n",
    "    Use StandardScaler() on numerical features if necessary.\n",
    "    Return a list of pipelines.\n",
    "    \"\"\"\n",
    "    num_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 37, 38, 39, 40,\n",
    "                   41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]\n",
    "    num_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, num_indices)], remainder=\"passthrough\")\n",
    "    \n",
    "    lasso = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                            (\"regressor\", LassoCV(cv=5, max_iter=500))])\n",
    "    ridge = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"regressor\", RidgeCV(cv=5))])\n",
    "    rf_regr = Pipeline(steps=[(\"regressor\", RandomForestRegressor(n_estimators=100))])\n",
    "    pipelines = [lasso, ridge, rf_regr]\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit models with train data\n",
    "# look at model performance on test data\n",
    "# evaluation metrics include r^2, mean absolute error and median absolute error\n",
    "regr_pipelines = regr_pipeline()\n",
    "regr_eval = []\n",
    "\n",
    "for pipeline in regr_pipelines:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    model_name = pipeline.named_steps['regressor'].__class__.__name__.split('.')[-1]\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    medae = median_absolute_error(y_test, y_pred)\n",
    "    regr_eval.append([model_name, r2, mae, medae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at evaluation metrics\n",
    "regr_eval = pd.DataFrame(regr_eval)\n",
    "regr_eval.columns = [\"model\", \"r2\", \"mean absolute error\", \"median absolute error\"]\n",
    "regr_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b). Binary Classification\n",
    "Using regression models results in large median absolute errors, so we thought classification models may actually make more sense for this problem. All features except for news url and timedelta were included in the model. StandardScaler() was applied to numerical features. Pipelines were created for each classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: insert distribution with different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the mean number of shares (3395) is used as the threshold, the popular and unpopular classes would be imbalanced. Additionally, the large range of number of shares would make the mean not appropriate to divide the news into two classes. Therefore, we decided to choose the median number of shares as the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the median number of shares as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with two classes, 0 for unpopular (shares <= 1400) and 1 for popular (shares > 1400)\n",
    "median = np.median(news[\"shares\"])\n",
    "news_binary_median = news.assign(popularity=0)\n",
    "news_binary_median.loc[news_binary_median[\"shares\"] > median, \"popularity\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose features and target\n",
    "X = news_binary_median.iloc[:, 2:60]  # all columns except url, timedelta and target\n",
    "y = news_binary_median[\"popularity\"].values.ravel()  # target: popularity (two classes, 0 and 1)\n",
    "\n",
    "# train test split using 80-20 rule\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create pipelines for different classification algorithms\n",
    "def clf_pipeline():\n",
    "    \"\"\"\n",
    "    Create a pipeline for each classification algorithm:\n",
    "    1. Logistic Regression\n",
    "    2. K-Nearest Neighbors\n",
    "    3. Naive Bayes\n",
    "    4. Random Forest Classifier\n",
    "    \n",
    "    Use StandardScaler() on numerical features if necessary.\n",
    "    Return a list of pipelines.\n",
    "    \"\"\"\n",
    "    num_indices = list(range(11)) + list(range(17, 29)) + list(range(37, 58))  # numerical feature indices\n",
    "    num_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, num_indices)], remainder=\"passthrough\")\n",
    "    \n",
    "    logistic = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                               (\"clf\", LogisticRegressionCV(cv=5, max_iter=250, solver=\"lbfgs\"))])\n",
    "    knn = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", KNeighborsClassifier())])\n",
    "    bayes = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"clf\", GaussianNB())])\n",
    "    rf_clf = Pipeline(steps=[(\"clf\", RandomForestClassifier(n_estimators=100))])\n",
    "    pipelines = [logistic, knn, bayes, rf_clf]\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit models with train data\n",
    "# look at model performance on test data\n",
    "# evaluation metrics include accuracy, precision, recall, f1 score, confusion_matrix and classification report\n",
    "clf_pipelines = clf_pipeline()\n",
    "clf_eval = []\n",
    "\n",
    "for pipeline in clf_pipelines:\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    model_name = pipeline.named_steps['clf'].__class__.__name__.split('.')[-1]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    clf_report = classification_report(y_test, y_pred)\n",
    "    clf_eval.append([model_name, accuracy, precision, recall, f1, conf_mat, clf_report])\n",
    "\n",
    "# store evaluation metrics in a dataframe\n",
    "clf_eval = pd.DataFrame(clf_eval)\n",
    "clf_eval.columns = [\"model\", \"accuracy\", \"precision\", \"recall\", \"f1 score\", \"confusion matrix\",\n",
    "                    \"classification report\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at model accuracy, precision, recall and F1 score of test data\n",
    "clf_eval[[\"model\", \"accuracy\", \"precision\", \"recall\", \"f1 score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at model confusion matrix of test data\n",
    "plt.figure(figsize=(11, 8.5))\n",
    "for idx in range(4):\n",
    "    plt.subplot(2, 2, idx + 1)\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.4)\n",
    "    ax = sns.heatmap(clf_eval[\"confusion matrix\"][idx], cmap=\"Blues\", annot=True, annot_kws={\"size\": 18}, fmt=\"d\")\n",
    "    ax.set_title(f\"{clf_eval['model'][idx]}\", size=16)\n",
    "    ax.xaxis.set_ticklabels([\"unpopular\", \"popular\"], size=14)\n",
    "    ax.yaxis.set_ticklabels([\"unpopular\", \"popular\"], size=14, rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\\\n",
    "Grid search and random search were too slow for this dataset. Instead, we used cross validation scores with cv = 5 and manually tuned some hyperparameters of the random forest classifier, including n_estimators, min_samples_leaf and max_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10, cross validation scores: [0.62656942 0.62350799 0.61205663 0.61527021 0.62130108]\n",
      "n_estimators: 30, cross validation scores: [0.64963143 0.64440237 0.64430475 0.65028152 0.65700471]\n",
      "n_estimators: 50, cross validation scores: [0.65805061 0.6516759  0.6397617  0.65558227 0.65705439]\n",
      "n_estimators: 70, cross validation scores: [0.66138772 0.64720973 0.64688532 0.66118354 0.66034694]\n",
      "n_estimators: 90, cross validation scores: [0.65947998 0.6573187  0.654972   0.66725231 0.66812291]\n",
      "n_estimators: 110, cross validation scores: [0.67055151 0.66094996 0.65490839 0.67084481 0.66642662]\n",
      "n_estimators: 130, cross validation scores: [0.66410996 0.65685285 0.65400632 0.66629463 0.66870188]\n"
     ]
    }
   ],
   "source": [
    "# tune n_estimators\n",
    "for num in range(10, 140, 20):\n",
    "    rf = RandomForestClassifier(n_estimators=num)\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=5, scoring=\"f1_weighted\")\n",
    "    print(f\"n_estimators: {num}, cross validation scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features: 4, cross validation scores: [0.66110923 0.65933961 0.65562667 0.66357436 0.66765261]\n",
      "max_features: 5, cross validation scores: [0.67135996 0.65701913 0.65147048 0.67013249 0.66333716]\n",
      "max_features: 6, cross validation scores: [0.66882618 0.65258678 0.65159386 0.66463172 0.66658734]\n",
      "max_features: 7, cross validation scores: [0.66599278 0.64849305 0.64991787 0.66046598 0.66712343]\n",
      "max_features: 8, cross validation scores: [0.66707609 0.65937483 0.6521839  0.66456739 0.67100549]\n"
     ]
    }
   ],
   "source": [
    "# choose n_estimators = 110\n",
    "# tune max_features\n",
    "for num in range(4, 9, 1):\n",
    "    rf = RandomForestClassifier(n_estimators=110, max_features=num)\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=5, scoring=\"f1_weighted\")\n",
    "    print(f\"max_features: {num}, cross validation scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_leaf: 1, cross validation scores: [0.67212606 0.66076646 0.65279281 0.66562271 0.66887121]\n",
      "min_samples_leaf: 3, cross validation scores: [0.67151023 0.66458395 0.65217652 0.66581511 0.67043162]\n",
      "min_samples_leaf: 5, cross validation scores: [0.67009837 0.6593832  0.65419266 0.66833512 0.66598092]\n",
      "min_samples_leaf: 7, cross validation scores: [0.66883908 0.66456808 0.65283642 0.67056486 0.67017003]\n"
     ]
    }
   ],
   "source": [
    "# choose n_estimators = 110 and max_features = 5\n",
    "# tune min_samples_leaf\n",
    "for num in range(1, 9, 2):\n",
    "    rf = RandomForestClassifier(n_estimators=110, max_features=5, min_samples_leaf=num)\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=5, scoring=\"f1_weighted\")\n",
    "    print(f\"min_samples_leaf: {num}, cross validation scores: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of manually tuning, we noticed that tuning max_features and min_samples_leaf gave very similar results when varying the numbers. Considering the combination of F1 score and efficiency, we decided to choose n_estimators = 100, max_features = 5 and min_samples_leaf = 7 for our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=5, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=7, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=110,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit final model with train data\n",
    "final_model = RandomForestClassifier(n_estimators=110, max_features=5, min_samples_leaf=7)\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6674233825198638, F1 Score: 0.6660757249588452\n"
     ]
    }
   ],
   "source": [
    "# North Star Metric: F1 Score\n",
    "# performance on test data\n",
    "y_pred = final_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}, F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "ax = sns.heatmap(conf_mat, cmap=\"Blues\", annot=True, annot_kws={\"size\": 18}, fmt=\"d\")\n",
    "ax.set_title(f\"Confusion Matrix of Final Model\", size=16)\n",
    "ax.xaxis.set_ticklabels([\"unpopular\", \"popular\"], size=14)\n",
    "ax.yaxis.set_ticklabels([\"unpopular\", \"popular\"], size=14, rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature importance \n",
    "imp = importances(final_model, X_test, pd.DataFrame(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot top 10 feature importance\n",
    "imp_top10 = imp[:10].reset_index()\n",
    "plt.figure(figsize=(8, 6), dpi=100)\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=imp_top10)\n",
    "plt.title(\"Top 10 Important Features\", size=20)\n",
    "plt.xlabel(\"Importance\", size=12)\n",
    "plt.xticks(size=10)\n",
    "plt.ylabel(\"Features\", size=12)\n",
    "plt.yticks(size=10)\n",
    "plt.savefig(fname=\"Importance Features\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "For this project, we initially tried to predict the number of shares of a piece of news with regression models. We fitted three algorithms, **Lasso**, **Ridge** and **Random Forest Regressor**, and found that the median absolute error (MedAE) was around 1600, which is very high considering that some news only has a few hundred shares.\\\n",
    "\\\n",
    "We then treated this problem as classification and used the median number of shares (1400) as a threshold to divide the news into two classes, popular and unpopular. We fitted four algorithms, **Logistic Regression**, **K-Nearest Neighbors**, **Gaussian Naive Bayes** and **Random Forest Classifier**, and found that **Random Forest Classifier** has the best performance using F1 score as North Star Metric.\\\n",
    "\\\n",
    "We manually tuned the hyperparameters of random forest classifier based on cross validation scores since grid/random search is too slow for this dataset. Our final model had a **F1 score of 0.67** and **accuracy of 67%** for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "- Choose an appropriate analysis method (regression/classification)\n",
    "- Recommendations for reporters and business entities:\\\n",
    "(1) Keywords are important.\\\n",
    "(2) Publication time matters.\\\n",
    "(3) Referencing articles with high popularity would be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
